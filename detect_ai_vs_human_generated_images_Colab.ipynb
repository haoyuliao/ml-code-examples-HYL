{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOMTkcjTIDT385ju2lgjES3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/haoyuliao/ml-code-examples-HYL/blob/main/detect_ai_vs_human_generated_images_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2025-03-07T22:23:21.696815Z",
          "iopub.status.busy": "2025-03-07T22:23:21.696590Z",
          "iopub.status.idle": "2025-03-07T22:23:31.029034Z",
          "shell.execute_reply": "2025-03-07T22:23:31.028097Z"
        },
        "papermill": {
          "duration": 9.339813,
          "end_time": "2025-03-07T22:23:31.030736",
          "exception": false,
          "start_time": "2025-03-07T22:23:21.690923",
          "status": "completed"
        },
        "tags": [],
        "id": "bfa11a15"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import copy\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.utils.data import Dataset, DataLoader, Subset, random_split\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.transforms.v2 as T\n",
        "from torchvision.models import convnext_base\n",
        "from torchvision.models.vision_transformer import vit_b_16, vit_l_16\n",
        "from PIL import Image, ImageFilter\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "import shutil\n"
      ]
    }
  ]
}